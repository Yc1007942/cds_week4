{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16d7578e",
   "metadata": {},
   "source": [
    "# Week 4 — Academic Success Predictor (EDM)\n",
    "\n",
    "You are the teaching team's **lead data scientists**. Using a (synthetic) pre-course survey dataset, you will:\n",
    "\n",
    "- explore the cohort’s baseline readiness\n",
    "- engineer meaningful features\n",
    "- build a predictive model using **PyTorch `nn.Linear`** (regression or classification)\n",
    "- design a simple **At‑Risk Intervention** alert\n",
    "\n",
    "**Important**\n",
    "- This dataset (`student_success_survey.csv`) is **synthetic** and created for learning.\n",
    "- Do **not** use `student_uid` as a predictive feature (it is an identifier).\n",
    "\n",
    "---\n",
    "\n",
    "## Learning goals\n",
    "- Practice real-world preprocessing: missing values, encoding, scaling\n",
    "- Build a clean ML pipeline and avoid leakage\n",
    "- Compare regression vs classification framing\n",
    "- Interpret linear model weights and discuss limitations\n",
    "- Translate predictions into actionable interventions (ethics-aware)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abe425a",
   "metadata": {},
   "source": [
    "## 0) Setup & reproducibility\n",
    "\n",
    "Run this cell first. If you are using **Google Colab**, you usually already have `pandas`, `sklearn`, and `torch` installed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c880150",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device:\", DEVICE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e251185",
   "metadata": {},
   "source": [
    "## 1) Load the dataset\n",
    "\n",
    "Place `student_success_survey.csv` in the same folder as this notebook.\n",
    "\n",
    "**Colab tip**: upload the CSV from your computer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a14f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you're in Colab, uncomment this:\n",
    "# from google.colab import files\n",
    "# files.upload()  # select student_success_survey.csv\n",
    "\n",
    "DATA_PATH = \"student_success_survey.csv\"  # adjust if needed\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print(df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d68d566",
   "metadata": {},
   "source": [
    "### Quick sanity checks\n",
    "\n",
    "✅ You should see ~200+ rows and ~20–30 columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07588bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bffb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values per column\n",
    "(df.isna().mean().sort_values(ascending=False) * 100).round(1).head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90944e4e",
   "metadata": {},
   "source": [
    "## 2) Understand the features (data dictionary)\n",
    "\n",
    "The dataset is derived from the course survey form. Key groups:\n",
    "\n",
    "- **Academic background**: `pillar`, `current_term`, `cgpa`, `prereq_ct_grade`\n",
    "- **Experience**: `used_pytorch_tensorflow`, `used_big_data_tools`\n",
    "- **Diagnostic** (multiple-choice): `diag_*_answer`\n",
    "- **Grit (Likert 1–5)**: `grit_*`\n",
    "- **Self‑efficacy (Likert 1–5)**: `cse_*`\n",
    "- **Logistics**: `hours_per_week_planned`, `commute_minutes_daily`, `team_*`, `laptop_*`\n",
    "\n",
    "**Target variable**\n",
    "- `final_course_score` (0–100): a synthetic proxy for final performance.\n",
    "\n",
    "---\n",
    "\n",
    "### Your first decision (Task 1): Regression or Classification?\n",
    "Pick one:\n",
    "\n",
    "- **A. Regression**: predict `final_course_score` directly.\n",
    "- **B. Classification**: predict a binary label (e.g. **Distinction** vs **Non‑Distinction**).\n",
    "\n",
    "You will implement the model as **one linear layer** using PyTorch: `nn.Linear`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac6b17f",
   "metadata": {},
   "source": [
    "## 3) Feature engineering (scaffold)\n",
    "\n",
    "Create at least **two engineered features**.\n",
    "\n",
    "Suggested ideas:\n",
    "1. **Grit score**: average the grit items **with reverse‑coding where appropriate**.\n",
    "2. **Technical readiness**: combine diagnostic correctness + experience.\n",
    "3. **Time budget score**: e.g., `hours_per_week_planned - commute_minutes_daily/60`.\n",
    "\n",
    "⚠️ Reverse-coded grit items in this dataset:\n",
    "- `grit_distracted_by_new_ideas`\n",
    "- `grit_short_term_obsession_then_loss`\n",
    "- `grit_i_change_goals`\n",
    "\n",
    "Reverse-coding rule for a 1–5 scale: `reversed = 6 - original`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47daadd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Engineer at least TWO features.\n",
    "\n",
    "GRIT_POS = [\n",
    "    \"grit_setbacks_dont_discourage_me\",\n",
    "    \"grit_i_am_a_hard_worker\",\n",
    "    \"grit_i_finish_what_i_begin\",\n",
    "]\n",
    "\n",
    "GRIT_NEG = [\n",
    "    \"grit_distracted_by_new_ideas\",\n",
    "    \"grit_short_term_obsession_then_loss\",\n",
    "    \"grit_i_change_goals\",\n",
    "]\n",
    "\n",
    "# Reverse-code the negative items\n",
    "for col in GRIT_NEG:\n",
    "    df[col + \"_rev\"] = 6 - df[col]\n",
    "\n",
    "# Example engineered feature 1: average grit\n",
    "df[\"avg_grit\"] = df[GRIT_POS + [c + \"_rev\" for c in GRIT_NEG]].mean(axis=1)\n",
    "\n",
    "# TODO: engineered feature 2 (pick one idea above)\n",
    "# df[\"tech_readiness\"] = ...\n",
    "\n",
    "# Quick check\n",
    "df[[\"avg_grit\"]].describe().T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb28c4e6",
   "metadata": {},
   "source": [
    "## 4) Exploratory Data Analysis (EDA)\n",
    "\n",
    "Answer these questions with visuals + 2–4 sentences each:\n",
    "\n",
    "1. Does **grit** correlate with **planned hours per week**?\n",
    "2. Is **CGPA** roughly linearly related to **final_course_score**?\n",
    "3. Are there obvious group differences by `pillar`?\n",
    "\n",
    "Tip: keep plots readable; label axes; include titles.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d11b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1 Grit vs hours\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.scatter(df[\"avg_grit\"], df[\"hours_per_week_planned\"], alpha=0.6)\n",
    "plt.xlabel(\"avg_grit\")\n",
    "plt.ylabel(\"hours_per_week_planned\")\n",
    "plt.title(\"Grit vs Planned Hours\")\n",
    "plt.grid(True, alpha=0.2)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f55836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2 CGPA vs final score\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.scatter(df[\"cgpa\"], df[\"final_course_score\"], alpha=0.6)\n",
    "plt.xlabel(\"cgpa\")\n",
    "plt.ylabel(\"final_course_score\")\n",
    "plt.title(\"CGPA vs Final Course Score\")\n",
    "plt.grid(True, alpha=0.2)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d41629b",
   "metadata": {},
   "source": [
    "## 5) Preprocessing (no leakage)\n",
    "\n",
    "We will:\n",
    "- split into train/test\n",
    "- impute missing values\n",
    "- standardize numeric features\n",
    "- one-hot encode categorical features\n",
    "\n",
    "✅ This produces a single numeric design matrix that you can feed into `nn.Linear`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8878dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = \"final_course_score\"\n",
    "\n",
    "# Define your feature set (edit this!)\n",
    "NUMERIC_FEATURES = [\n",
    "    \"cgpa\",\n",
    "    \"hours_per_week_planned\",\n",
    "    \"commute_minutes_daily\",\n",
    "    \"avg_grit\",\n",
    "    # TODO: add your engineered features here\n",
    "]\n",
    "\n",
    "CATEGORICAL_FEATURES = [\n",
    "    \"pillar\",\n",
    "    \"current_term\",\n",
    "    \"prereq_ct_grade\",\n",
    "    \"used_pytorch_tensorflow\",\n",
    "    \"used_big_data_tools\",\n",
    "    \"diag_python_mod_answer\",\n",
    "    \"diag_pvalue_answer\",\n",
    "    \"diag_pca_answer\",\n",
    "    \"team_formed_for_final_project\",\n",
    "    \"laptop_or_cloud_ready\",\n",
    "]\n",
    "\n",
    "feature_cols = NUMERIC_FEATURES + CATEGORICAL_FEATURES\n",
    "\n",
    "X = df[feature_cols].copy()\n",
    "y = df[TARGET].copy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=SEED\n",
    ")\n",
    "\n",
    "numeric_pipe = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# scikit-learn changed this arg name; support both.\n",
    "try:\n",
    "    onehot = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "except TypeError:\n",
    "    onehot = OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\n",
    "\n",
    "categorical_pipe = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"onehot\", onehot),\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_pipe, NUMERIC_FEATURES),\n",
    "        (\"cat\", categorical_pipe, CATEGORICAL_FEATURES),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    ")\n",
    "\n",
    "X_train_np = preprocess.fit_transform(X_train)\n",
    "X_test_np = preprocess.transform(X_test)\n",
    "\n",
    "print(\"X_train shape:\", X_train_np.shape)\n",
    "print(\"X_test shape:\", X_test_np.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4deecef0",
   "metadata": {},
   "source": [
    "## 6) Modeling with PyTorch `nn.Linear`\n",
    "\n",
    "You will implement a **single-layer linear model**.\n",
    "\n",
    "### Option A — Regression (MSE)\n",
    "- loss: `nn.MSELoss()`\n",
    "- metrics: MSE, R²\n",
    "\n",
    "### Option B — Classification (BCEWithLogits)\n",
    "- create a binary target label (e.g. distinction = score ≥ threshold)\n",
    "- loss: `nn.BCEWithLogitsLoss()`\n",
    "- metrics: confusion matrix, precision, recall, F1\n",
    "\n",
    "---\n",
    "\n",
    "### Starter: model + training loop (works for regression)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b40a4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StudentSuccessLinear(nn.Module):\n",
    "    def __init__(self, input_dim: int):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_dim, 1)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.linear(x)\n",
    "\n",
    "\n",
    "def make_loaders(X_train_np, y_train_np, X_test_np, y_test_np, batch_size=32):\n",
    "    X_train_t = torch.tensor(X_train_np, dtype=torch.float32)\n",
    "    y_train_t = torch.tensor(y_train_np, dtype=torch.float32).view(-1, 1)\n",
    "    X_test_t = torch.tensor(X_test_np, dtype=torch.float32)\n",
    "    y_test_t = torch.tensor(y_test_np, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        TensorDataset(X_train_t, y_train_t), batch_size=batch_size, shuffle=True\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        TensorDataset(X_test_t, y_test_t), batch_size=batch_size, shuffle=False\n",
    "    )\n",
    "    return train_loader, test_loader\n",
    "\n",
    "\n",
    "def train_regression(model, train_loader, test_loader, epochs=300, lr=1e-2):\n",
    "    model = model.to(DEVICE)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "        for xb, yb in train_loader:\n",
    "            xb = xb.to(DEVICE)\n",
    "            yb = yb.to(DEVICE)\n",
    "\n",
    "            pred = model(xb)\n",
    "            loss = criterion(pred, yb)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item() * xb.size(0)\n",
    "\n",
    "        train_losses.append(epoch_loss / len(train_loader.dataset))\n",
    "\n",
    "        # eval\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            total = 0.0\n",
    "            for xb, yb in test_loader:\n",
    "                xb = xb.to(DEVICE)\n",
    "                yb = yb.to(DEVICE)\n",
    "                pred = model(xb)\n",
    "                loss = criterion(pred, yb)\n",
    "                total += loss.item() * xb.size(0)\n",
    "            test_losses.append(total / len(test_loader.dataset))\n",
    "\n",
    "        if epoch % 50 == 0:\n",
    "            print(f\"Epoch {epoch:4d} | train MSE {train_losses[-1]:.3f} | test MSE {test_losses[-1]:.3f}\")\n",
    "\n",
    "    return train_losses, test_losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8fc2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline: regression model\n",
    "\n",
    "train_loader, test_loader = make_loaders(\n",
    "    X_train_np,\n",
    "    y_train.to_numpy(),\n",
    "    X_test_np,\n",
    "    y_test.to_numpy(),\n",
    "    batch_size=32,\n",
    ")\n",
    "\n",
    "model = StudentSuccessLinear(input_dim=X_train_np.shape[1])\n",
    "train_losses, test_losses = train_regression(model, train_loader, test_loader, epochs=300, lr=1e-2)\n",
    "\n",
    "# Plot loss curves\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(train_losses, label=\"train\")\n",
    "plt.plot(test_losses, label=\"test\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.title(\"Training vs Test Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.2)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2304dfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate regression (MSE, R^2)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    X_test_t = torch.tensor(X_test_np, dtype=torch.float32).to(DEVICE)\n",
    "    preds = model(X_test_t).cpu().numpy().reshape(-1)\n",
    "\n",
    "mse = mean_squared_error(y_test, preds)\n",
    "r2 = r2_score(y_test, preds)\n",
    "print(\"Test MSE:\", round(mse, 3))\n",
    "print(\"Test R2:\", round(r2, 3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62b4aa2",
   "metadata": {},
   "source": [
    "## 7) Your turn: improve the model\n",
    "\n",
    "Minimum requirements:\n",
    "- Add **≥2 engineered features**\n",
    "- Justify features with EDA\n",
    "- Train either:\n",
    "  - regression, or\n",
    "  - classification (you must pick a label definition + threshold)\n",
    "\n",
    "Stretch goals:\n",
    "- try L2 regularization (`weight_decay`)\n",
    "- compare regression vs classification framing\n",
    "- interpret weights: which features help/hurt predicted success?\n",
    "\n",
    "---\n",
    "\n",
    "### Optional: classification scaffold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2f873f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL (Classification)\n",
    "# Define a binary label. Example: distinction if score >= 85.\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "\n",
    "DISTINCTION_THRESHOLD = 80  # TODO: try different thresholds\n",
    "\n",
    "y_bin = (df[\"final_course_score\"] >= DISTINCTION_THRESHOLD).astype(int)\n",
    "print(\"Positive rate (label=1):\", float(y_bin.mean()))\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[feature_cols], y_bin, test_size=0.2, random_state=SEED, stratify=y_bin\n",
    ")\n",
    "\n",
    "X_train_np = preprocess.fit_transform(X_train)\n",
    "X_test_np = preprocess.transform(X_test)\n",
    "\n",
    "train_loader, test_loader = make_loaders(\n",
    "    X_train_np,\n",
    "    y_train.to_numpy(),\n",
    "    X_test_np,\n",
    "    y_test.to_numpy(),\n",
    "    batch_size=32,\n",
    ")\n",
    "\n",
    "model = StudentSuccessLinear(input_dim=X_train_np.shape[1]).to(DEVICE)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
    "\n",
    "EPOCHS = 300\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    model.train()\n",
    "    for xb, yb in train_loader:\n",
    "        xb = xb.to(DEVICE)\n",
    "        yb = yb.to(DEVICE)\n",
    "\n",
    "        logits = model(xb)\n",
    "        loss = criterion(logits, yb)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if epoch % 50 == 0:\n",
    "        print(\"epoch\", epoch, \"loss\", float(loss))\n",
    "\n",
    "# Evaluate\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    X_test_t = torch.tensor(X_test_np, dtype=torch.float32).to(DEVICE)\n",
    "    logits = model(X_test_t).cpu().numpy().reshape(-1)\n",
    "\n",
    "probs = 1 / (1 + np.exp(-logits))\n",
    "THRESHOLD = 0.5\n",
    "preds = (probs >= THRESHOLD).astype(int)\n",
    "\n",
    "cm = confusion_matrix(y_test, preds)\n",
    "print(\"Confusion matrix:\n",
    "\", cm)\n",
    "print(\"Precision:\", precision_score(y_test, preds))\n",
    "print(\"Recall:\", recall_score(y_test, preds))\n",
    "print(\"F1:\", f1_score(y_test, preds))\n",
    "\n",
    "# TODO: Tune THRESHOLD for higher Recall (why might that matter for at-risk alerts?)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8931c7e8",
   "metadata": {},
   "source": [
    "## 8) PCA: do students cluster by academic pillar?\n",
    "\n",
    "Use PCA on the **preprocessed design matrix** and visualize the first 2 components.\n",
    "\n",
    "Prompt:\n",
    "- Do you see clusters? If not, why might that be?\n",
    "- What does PCA *not* tell you?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f9977e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Fit PCA on the TRAIN matrix (no leakage)\n",
    "pca = PCA(n_components=2, random_state=SEED)\n",
    "Z = pca.fit_transform(X_train_np)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.scatter(Z[:, 0], Z[:, 1], alpha=0.6)\n",
    "plt.title(\"PCA of preprocessed features (train set)\")\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.grid(True, alpha=0.2)\n",
    "plt.show()\n",
    "\n",
    "print(\"Explained variance ratio:\", pca.explained_variance_ratio_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a168f21",
   "metadata": {},
   "source": [
    "## 9) The “At‑Risk Intervention Alert” (agentic add‑on)\n",
    "\n",
    "In educational data mining, prediction is only useful if it leads to **action**.\n",
    "\n",
    "Design a function that:\n",
    "- identifies at-risk students\n",
    "- outputs a **pedagogical recommendation** (specific + actionable)\n",
    "\n",
    "Examples of recommendations:\n",
    "- “Review Python basics: `2 % 3`, loops, lists”\n",
    "- “Attend Week 1–2 recap clinic”\n",
    "- “Form a project team early + schedule 2h/week study block”\n",
    "\n",
    "⚠️ Ethics: the alert should be supportive, not punitive.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a554885",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_intervention(row, predicted_score=None, threshold=70):\n",
    "    '''Return (risk_level, recommendation).\n",
    "\n",
    "    TODO: tune rules based on your EDA + model.\n",
    "    '''\n",
    "\n",
    "    # Example rule-based scaffold\n",
    "    if predicted_score is not None and predicted_score < threshold:\n",
    "        # Customize these rules\n",
    "        if row.get(\"hours_per_week_planned\") is not None and row.get(\"hours_per_week_planned\") < 5:\n",
    "            return \"high\", \"Increase weekly study plan to 6–8h; block it on your calendar.\"\n",
    "        if row.get(\"cgpa\") is not None and row.get(\"cgpa\") < 3.5:\n",
    "            return \"high\", \"Book a consult with TA; focus on foundations + weekly practice.\"\n",
    "        return \"medium\", \"Do the Week 1–2 refresher worksheet + attend office hours.\"\n",
    "\n",
    "    return \"low\", \"Keep up the good work; consider helping peers or taking stretch tasks.\"\n",
    "\n",
    "\n",
    "# Demo on one row (replace `predicted_score` with your model output)\n",
    "example = df.iloc[0].to_dict()\n",
    "recommend_intervention(example, predicted_score=65)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935f2d13",
   "metadata": {},
   "source": [
    "## Submission checklist\n",
    "\n",
    "Your notebook should:\n",
    "- run end-to-end without errors\n",
    "- include clear plots + short written interpretation\n",
    "- include feature engineering + justification\n",
    "- include a PyTorch `nn.Linear` model with training loop\n",
    "- include evaluation metrics + a short discussion of limitations\n",
    "- include the at-risk intervention function + ethical reflection\n",
    "\n",
    "---\n",
    "\n",
    "### Reflection prompts (write 3–6 sentences)\n",
    "- What would make this model *unsafe* to deploy in real life?\n",
    "- Which student groups might be disadvantaged by these features?\n",
    "- What additional data would you want, and why?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
