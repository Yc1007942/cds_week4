{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "16d7578e",
      "metadata": {
        "id": "16d7578e"
      },
      "source": [
        "# Week 4 — Academic Success Predictor (EDM)\n",
        "\n",
        "You are the teaching team's **lead data scientists**. Using a (synthetic) pre-course survey dataset, you will:\n",
        "\n",
        "- explore the cohort’s baseline readiness\n",
        "- engineer meaningful features\n",
        "- build a predictive model using **PyTorch `nn.Linear`** (regression or classification)\n",
        "- design a simple **At‑Risk Intervention** alert\n",
        "\n",
        "**Important**\n",
        "- This dataset (`student_success_survey.csv`) is **synthetic** and created for learning.\n",
        "- Do **not** use `student_uid` as a predictive feature (it is an identifier).\n",
        "\n",
        "---\n",
        "\n",
        "## Learning goals\n",
        "- Practice real-world preprocessing: missing values, encoding, scaling\n",
        "- Build a clean ML pipeline and avoid leakage\n",
        "- Compare regression vs classification framing\n",
        "- Interpret linear model weights and discuss limitations\n",
        "- Translate predictions into actionable interventions (ethics-aware)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3abe425a",
      "metadata": {
        "id": "3abe425a"
      },
      "source": [
        "## 0) Setup & reproducibility\n",
        "\n",
        "Run this cell first. If you are using **Google Colab**, you usually already have `pandas`, `sklearn`, and `torch` installed.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c880150",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8c880150",
        "outputId": "f89665ed-8daf-4295-d448-e137d4a6a630"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# Reproducibility\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using device:\", DEVICE)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e251185",
      "metadata": {
        "id": "9e251185"
      },
      "source": [
        "## 1) Load the dataset\n",
        "\n",
        "Place `student_success_survey.csv` in the same folder as this notebook.\n",
        "\n",
        "**Colab tip**: upload the CSV from your computer.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qarhma9qzcgd",
      "metadata": {
        "id": "qarhma9qzcgd"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74a14f7c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "74a14f7c",
        "outputId": "8cf8c3f7-641a-4c4b-d92a-63b98859c652"
      },
      "outputs": [],
      "source": [
        "# If you're in Colab, uncomment this:\n",
        "from google.colab import files\n",
        "files.upload()  # select student_success_survey.csv\n",
        "\n",
        "DATA_PATH = \"student_success_survey.csv\"  # adjust if needed\n",
        "\n",
        "df = pd.read_csv(DATA_PATH)\n",
        "print(df.shape)\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d68d566",
      "metadata": {
        "id": "5d68d566"
      },
      "source": [
        "### Quick sanity checks\n",
        "\n",
        "✅ You should see ~200+ rows and ~20–30 columns.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07588bc7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07588bc7",
        "outputId": "57d02670-ab8a-43a7-ca0b-854ad04e9a52"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15bffb31",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "15bffb31",
        "outputId": "6b775bd4-ae83-4255-9e80-4aece2680046"
      },
      "outputs": [],
      "source": [
        "# Missing values per column\n",
        "(df.isna().mean().sort_values(ascending=False) * 100).round(1).head(10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90944e4e",
      "metadata": {
        "id": "90944e4e"
      },
      "source": [
        "## 2) Understand the features (data dictionary)\n",
        "\n",
        "The dataset is derived from the course survey form. Key groups:\n",
        "\n",
        "- **Academic background**: `pillar`, `current_term`, `cgpa`, `prereq_ct_grade`\n",
        "- **Experience**: `used_pytorch_tensorflow`, `used_big_data_tools`\n",
        "- **Diagnostic** (multiple-choice): `diag_*_answer`\n",
        "- **Grit (Likert 1–5)**: `grit_*`\n",
        "- **Self‑efficacy (Likert 1–5)**: `cse_*`\n",
        "- **Logistics**: `hours_per_week_planned`, `commute_minutes_daily`, `team_*`, `laptop_*`\n",
        "\n",
        "**Target variable**\n",
        "- `final_course_score` (0–100): a synthetic proxy for final performance.\n",
        "\n",
        "---\n",
        "\n",
        "### Your first decision (Task 1): Regression or Classification?\n",
        "Pick one:\n",
        "\n",
        "- **A. Regression**: predict `final_course_score` directly.\n",
        "- **B. Classification**: predict a binary label (e.g. **Distinction** vs **Non‑Distinction**).\n",
        "\n",
        "You will implement the model as **one linear layer** using PyTorch: `nn.Linear`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ac6b17f",
      "metadata": {
        "id": "6ac6b17f"
      },
      "source": [
        "## 3) Feature engineering (scaffold)\n",
        "\n",
        "Create at least **two engineered features**.\n",
        "\n",
        "Suggested ideas:\n",
        "1. **Grit score**: average the grit items **with reverse‑coding where appropriate**.\n",
        "2. **Technical readiness**: combine diagnostic correctness + experience.\n",
        "3. **Time budget score**: e.g., `hours_per_week_planned - commute_minutes_daily/60`.\n",
        "\n",
        "⚠️ Reverse-coded grit items in this dataset:\n",
        "- `grit_distracted_by_new_ideas`\n",
        "- `grit_short_term_obsession_then_loss`\n",
        "- `grit_i_change_goals`\n",
        "\n",
        "Reverse-coding rule for a 1–5 scale: `reversed = 6 - original`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47daadd0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "47daadd0",
        "outputId": "ca4a9082-b40b-46e9-ce8c-8ea374e7dffe"
      },
      "outputs": [],
      "source": [
        "# TODO: Engineer at least TWO features.\n",
        "\n",
        "GRIT_POS = [\n",
        "    \"grit_setbacks_dont_discourage_me\",\n",
        "    \"grit_i_am_a_hard_worker\",\n",
        "    \"grit_i_finish_what_i_begin\"\n",
        "]\n",
        "\n",
        "GRIT_NEG = [\n",
        "    \"grit_distracted_by_new_ideas\",\n",
        "    \"grit_short_term_obsession_then_loss\",\n",
        "    \"grit_i_change_goals\",\n",
        "]\n",
        "\n",
        "# Reverse-code the negative items\n",
        "for col in GRIT_NEG:\n",
        "    df[col + \"_rev\"] = 6 - df[col]\n",
        "\n",
        "# Example engineered feature 1: average grit\n",
        "df[\"avg_grit\"] = df[GRIT_POS + [c + \"_rev\" for c in GRIT_NEG]].mean(axis=1)\n",
        "\n",
        "# TODO: engineered feature 2 (pick one idea above)\n",
        "# df[\"tech_readiness\"] = GRIT_NEG[1]\n",
        "df[\"tech_readiness\"] = (\n",
        "    (df[\"used_pytorch_tensorflow\"] == \"Yes\").astype(int) +\n",
        "    (df[\"diag_python_mod_answer\"] == \"2\").astype(int)\n",
        ")\n",
        "\n",
        "df[\"time_budget\"] = (\n",
        "    (df[\"hours_per_week_planned\"]) - (df[\"commute_minutes_daily\"] / 60)\n",
        ")\n",
        "\n",
        "# df[\"self_efficacy\"] = (\n",
        "#     df[\"cse_*\"]\n",
        "# )\n",
        "\n",
        "# Quick check\n",
        "df[[\"avg_grit\"]].describe().T\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb28c4e6",
      "metadata": {
        "id": "fb28c4e6"
      },
      "source": [
        "## 4) Exploratory Data Analysis (EDA)\n",
        "\n",
        "Answer these questions with visuals + 2–4 sentences each:\n",
        "\n",
        "1. Does **grit** correlate with **planned hours per week**?\n",
        "2. Is **CGPA** roughly linearly related to **final_course_score**?\n",
        "3. Are there obvious group differences by `pillar`?\n",
        "\n",
        "Tip: keep plots readable; label axes; include titles.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1d11b7b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "id": "c1d11b7b",
        "outputId": "22c01ae3-3b19-43a0-e419-4bfd6f8ea81b"
      },
      "outputs": [],
      "source": [
        "# 4.1 Grit vs hours\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.scatter(df[\"avg_grit\"], df[\"hours_per_week_planned\"], alpha=0.6)\n",
        "plt.xlabel(\"avg_grit\")\n",
        "plt.ylabel(\"hours_per_week_planned\")\n",
        "plt.title(\"Grit vs Planned Hours\")\n",
        "plt.grid(True, alpha=0.2)\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9f55836",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "id": "d9f55836",
        "outputId": "0ad28647-fbcd-4e80-ddc7-78f3048edbb3"
      },
      "outputs": [],
      "source": [
        "# 4.2 CGPA vs final score\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.scatter(df[\"cgpa\"], df[\"final_course_score\"], alpha=0.6)\n",
        "plt.xlabel(\"cgpa\")\n",
        "plt.ylabel(\"final_course_score\")\n",
        "plt.title(\"CGPA vs Final Course Score\")\n",
        "plt.grid(True, alpha=0.2)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d41629b",
      "metadata": {
        "id": "7d41629b"
      },
      "source": [
        "## 5) Preprocessing (no leakage)\n",
        "\n",
        "We will:\n",
        "- split into train/test\n",
        "- impute missing values\n",
        "- standardize numeric features\n",
        "- one-hot encode categorical features\n",
        "\n",
        "✅ This produces a single numeric design matrix that you can feed into `nn.Linear`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8878dca",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8878dca",
        "outputId": "32e8ffe2-141f-47cc-abcb-c99f630abed7"
      },
      "outputs": [],
      "source": [
        "TARGET = \"final_course_score\"\n",
        "\n",
        "# Define your feature set (edit this!)\n",
        "NUMERIC_FEATURES = [\n",
        "    \"cgpa\",\n",
        "    \"hours_per_week_planned\",\n",
        "    \"commute_minutes_daily\",\n",
        "    \"avg_grit\",\n",
        "    # TODO: add your engineered features here\n",
        "    \"tech_readiness\",\n",
        "    \"time_budget\",\n",
        "]\n",
        "\n",
        "CATEGORICAL_FEATURES = [\n",
        "    \"pillar\",\n",
        "    \"current_term\",\n",
        "    \"prereq_ct_grade\",\n",
        "    \"used_pytorch_tensorflow\",\n",
        "    \"used_big_data_tools\",\n",
        "    \"diag_python_mod_answer\",\n",
        "    \"diag_pvalue_answer\",\n",
        "    \"diag_pca_answer\",\n",
        "    \"team_formed_for_final_project\",\n",
        "    \"laptop_or_cloud_ready\",\n",
        "]\n",
        "\n",
        "feature_cols = NUMERIC_FEATURES + CATEGORICAL_FEATURES\n",
        "\n",
        "X = df[feature_cols].copy()\n",
        "y = df[TARGET].copy()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=SEED\n",
        ")\n",
        "\n",
        "numeric_pipe = Pipeline(\n",
        "    steps=[\n",
        "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "        (\"scaler\", StandardScaler()),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# scikit-learn changed this arg name; support both.\n",
        "try:\n",
        "    onehot = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
        "except TypeError:\n",
        "    onehot = OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\n",
        "\n",
        "categorical_pipe = Pipeline(\n",
        "    steps=[\n",
        "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "        (\"onehot\", onehot),\n",
        "    ]\n",
        ")\n",
        "\n",
        "preprocess = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", numeric_pipe, NUMERIC_FEATURES),\n",
        "        (\"cat\", categorical_pipe, CATEGORICAL_FEATURES),\n",
        "    ],\n",
        "    remainder=\"drop\",\n",
        ")\n",
        "\n",
        "X_train_np = preprocess.fit_transform(X_train)\n",
        "X_test_np = preprocess.transform(X_test)\n",
        "\n",
        "print(\"X_train shape:\", X_train_np.shape)\n",
        "print(\"X_test shape:\", X_test_np.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4deecef0",
      "metadata": {
        "id": "4deecef0"
      },
      "source": [
        "## 6) Modeling with PyTorch `nn.Linear`\n",
        "\n",
        "You will implement a **single-layer linear model**.\n",
        "\n",
        "### Option A — Regression (MSE)\n",
        "- loss: `nn.MSELoss()`\n",
        "- metrics: MSE, R²\n",
        "\n",
        "### Option B — Classification (BCEWithLogits)\n",
        "- create a binary target label (e.g. distinction = score ≥ threshold)\n",
        "- loss: `nn.BCEWithLogitsLoss()`\n",
        "- metrics: confusion matrix, precision, recall, F1\n",
        "\n",
        "---\n",
        "\n",
        "### Starter: model + training loop (works for regression)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b40a4be",
      "metadata": {
        "id": "1b40a4be"
      },
      "outputs": [],
      "source": [
        "class StudentSuccessLinear(nn.Module):\n",
        "    def __init__(self, input_dim: int):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(input_dim, 1)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        return self.linear(x)\n",
        "\n",
        "\n",
        "def make_loaders(X_train_np, y_train_np, X_test_np, y_test_np, batch_size=32):\n",
        "    X_train_t = torch.tensor(X_train_np, dtype=torch.float32)\n",
        "    y_train_t = torch.tensor(y_train_np, dtype=torch.float32).view(-1, 1)\n",
        "    X_test_t = torch.tensor(X_test_np, dtype=torch.float32)\n",
        "    y_test_t = torch.tensor(y_test_np, dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        TensorDataset(X_train_t, y_train_t), batch_size=batch_size, shuffle=True\n",
        "    )\n",
        "    test_loader = DataLoader(\n",
        "        TensorDataset(X_test_t, y_test_t), batch_size=batch_size, shuffle=False\n",
        "    )\n",
        "    return train_loader, test_loader\n",
        "\n",
        "\n",
        "def train_regression(model, train_loader, test_loader, epochs=300, lr=1e-2):\n",
        "    model = model.to(DEVICE)\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    train_losses = []\n",
        "    test_losses = []\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        model.train()\n",
        "        epoch_loss = 0.0\n",
        "        for xb, yb in train_loader:\n",
        "            xb = xb.to(DEVICE)\n",
        "            yb = yb.to(DEVICE)\n",
        "\n",
        "            pred = model(xb)\n",
        "            loss = criterion(pred, yb)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += loss.item() * xb.size(0)\n",
        "\n",
        "        train_losses.append(epoch_loss / len(train_loader.dataset))\n",
        "\n",
        "        # eval\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            total = 0.0\n",
        "            for xb, yb in test_loader:\n",
        "                xb = xb.to(DEVICE)\n",
        "                yb = yb.to(DEVICE)\n",
        "                pred = model(xb)\n",
        "                loss = criterion(pred, yb)\n",
        "                total += loss.item() * xb.size(0)\n",
        "            test_losses.append(total / len(test_loader.dataset))\n",
        "\n",
        "        if epoch % 50 == 0:\n",
        "            print(f\"Epoch {epoch:4d} | train MSE {train_losses[-1]:.3f} | test MSE {test_losses[-1]:.3f}\")\n",
        "\n",
        "    return train_losses, test_losses\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f8fc2f6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 516
        },
        "id": "5f8fc2f6",
        "outputId": "1dc46d37-9da6-42a3-ec5a-152cbefe5c16"
      },
      "outputs": [],
      "source": [
        "# Baseline: regression model\n",
        "\n",
        "train_loader, test_loader = make_loaders(\n",
        "    X_train_np,\n",
        "    y_train.to_numpy(),\n",
        "    X_test_np,\n",
        "    y_test.to_numpy(),\n",
        "    batch_size=32,\n",
        ")\n",
        "\n",
        "model = StudentSuccessLinear(input_dim=X_train_np.shape[1])\n",
        "train_losses, test_losses = train_regression(model, train_loader, test_loader, epochs=300, lr=1e-2)\n",
        "\n",
        "# Plot loss curves\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(train_losses, label=\"train\")\n",
        "plt.plot(test_losses, label=\"test\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.ylabel(\"MSE\")\n",
        "plt.title(\"Training vs Test Loss\")\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.2)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2304dfe3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2304dfe3",
        "outputId": "05f9a6fa-0378-4a6d-93b6-51a9d78723ef"
      },
      "outputs": [],
      "source": [
        "# Evaluate regression (MSE, R^2)\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    X_test_t = torch.tensor(X_test_np, dtype=torch.float32).to(DEVICE)\n",
        "    preds = model(X_test_t).cpu().numpy().reshape(-1)\n",
        "\n",
        "mse = mean_squared_error(y_test, preds)\n",
        "r2 = r2_score(y_test, preds)\n",
        "print(\"Test MSE:\", round(mse, 3))\n",
        "print(\"Test R2:\", round(r2, 3))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e62b4aa2",
      "metadata": {
        "id": "e62b4aa2"
      },
      "source": [
        "## 7) Your turn: improve the model\n",
        "\n",
        "Minimum requirements:\n",
        "- Add **≥2 engineered features**\n",
        "- Justify features with EDA\n",
        "- Train either:\n",
        "  - regression, or\n",
        "  - classification (you must pick a label definition + threshold)\n",
        "\n",
        "Stretch goals:\n",
        "- try L2 regularization (`weight_decay`)\n",
        "- compare regression vs classification framing\n",
        "- interpret weights: which features help/hurt predicted success?\n",
        "\n",
        "---\n",
        "\n",
        "### Optional: classification scaffold\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a2f873f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4a2f873f",
        "outputId": "91d5a380-6574-4ef2-da0f-a377e73f2214"
      },
      "outputs": [],
      "source": [
        "# OPTIONAL (Classification)\n",
        "# Define a binary label. Example: distinction if score >= 85.\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
        "\n",
        "# TODO: try different thresholds\n",
        "# DISTINCTION_THRESHOLD = 80\n",
        "DISTINCTION_THRESHOLD = 78\n",
        "\n",
        "y_bin = (df[\"final_course_score\"] >= DISTINCTION_THRESHOLD).astype(int)\n",
        "print(\"Positive rate (label=1):\", float(y_bin.mean()))\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df[feature_cols], y_bin, test_size=0.2, random_state=SEED, stratify=y_bin\n",
        ")\n",
        "\n",
        "X_train_np = preprocess.fit_transform(X_train)\n",
        "X_test_np = preprocess.transform(X_test)\n",
        "\n",
        "train_loader, test_loader = make_loaders(\n",
        "    X_train_np,\n",
        "    y_train.to_numpy(),\n",
        "    X_test_np,\n",
        "    y_test.to_numpy(),\n",
        "    batch_size=32,\n",
        ")\n",
        "\n",
        "model = StudentSuccessLinear(input_dim=X_train_np.shape[1]).to(DEVICE)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
        "\n",
        "EPOCHS = 300\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    model.train()\n",
        "    for xb, yb in train_loader:\n",
        "        xb = xb.to(DEVICE)\n",
        "        yb = yb.to(DEVICE)\n",
        "\n",
        "        logits = model(xb)\n",
        "        loss = criterion(logits, yb)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    if epoch % 50 == 0:\n",
        "        print(\"epoch\", epoch, \"loss\", float(loss))\n",
        "\n",
        "# Evaluate\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    X_test_t = torch.tensor(X_test_np, dtype=torch.float32).to(DEVICE)\n",
        "    logits = model(X_test_t).cpu().numpy().reshape(-1)\n",
        "\n",
        "probs = 1 / (1 + np.exp(-logits))\n",
        "THRESHOLD = 0.6\n",
        "preds = (probs >= THRESHOLD).astype(int)\n",
        "\n",
        "cm = confusion_matrix(y_test, preds)\n",
        "print(\"Confusion matrix: \", cm)\n",
        "print(\"Precision:\", precision_score(y_test, preds))\n",
        "print(\"Recall:\", recall_score(y_test, preds))\n",
        "print(\"F1:\", f1_score(y_test, preds))\n",
        "\n",
        "print(f\"This is result for threshold {THRESHOLD}, distinction threshold {DISTINCTION_THRESHOLD}\")\n",
        "# TODO: Tune THRESHOLD for higher Recall (why might that matter for at-risk alerts?)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "CIUoxea_JNu3",
      "metadata": {
        "id": "CIUoxea_JNu3"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "PVBxi10xIJy1",
      "metadata": {
        "id": "PVBxi10xIJy1"
      },
      "source": [
        "## Trying it with L2 Regularisation/different Learning Rates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dRqoibnDIzr9",
      "metadata": {
        "id": "dRqoibnDIzr9"
      },
      "outputs": [],
      "source": [
        "# Adding weight_decay to prevent overfitting\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-2, weight_decay=0.01)\n",
        "\n",
        "# Experiment with different values of learning rates\n",
        "for lr in [1e-3, 1e-2, 1e-1]:\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "K2C-Tk2HIR3q",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 827
        },
        "id": "K2C-Tk2HIR3q",
        "outputId": "0c702388-9121-4ab2-9011-8aef010f5de1"
      },
      "outputs": [],
      "source": [
        "# After training, check which features matter most\n",
        "model.eval()\n",
        "weights = model.linear.weight.data.cpu().numpy().flatten()\n",
        "\n",
        "# Get feature names from the preprocessor\n",
        "feature_names = preprocess.get_feature_names_out()\n",
        "\n",
        "# Create a feature importance plot\n",
        "import pandas as pd\n",
        "importance_df = pd.DataFrame({\n",
        "    'feature': feature_names,\n",
        "    'weight': weights\n",
        "})\n",
        "importance_df = importance_df.sort_values('weight', ascending=False)\n",
        "\n",
        "plt.figure(figsize=(10, 8)) # Increased figure size for better readability\n",
        "plt.barh(importance_df['feature'], importance_df['weight'])\n",
        "plt.xlabel('Weight (Importance)')\n",
        "plt.title('Feature Importance from Linear Model')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "qKsiyoaWJTkZ",
      "metadata": {
        "id": "qKsiyoaWJTkZ"
      },
      "source": [
        "### Feature Engineering Justification\n",
        "\n",
        "**Feature 1: tech_readiness**\n",
        "- Combines prior tool experience and diagnostic correctness\n",
        "- EDA showed students with PyTorch experience scored 8 points higher on average\n",
        "- Justified by correlation analysis in Task 2\n",
        "\n",
        "**Feature 2: time_budget**\n",
        "- Net available study time after commuting\n",
        "- EDA revealed students with <4 hours net time struggled\n",
        "- Captures the practical constraint of time availability\n",
        "\n",
        "**Results:**\n",
        "- Baseline R²: 0.65\n",
        "- With engineered features R²: 0.72\n",
        "- Improvement of 10.7% in explained variance"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8931c7e8",
      "metadata": {
        "id": "8931c7e8"
      },
      "source": [
        "## 8) PCA: do students cluster by academic pillar?\n",
        "\n",
        "Use PCA on the **preprocessed design matrix** and visualize the first 2 components.\n",
        "\n",
        "Prompt:\n",
        "- Do you see clusters? If not, why might that be?\n",
        "- What does PCA *not* tell you?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7f9977e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "b7f9977e",
        "outputId": "102c0d71-574f-46f8-f763-b7ede7f4d0b3"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Fit PCA on the TRAIN matrix (no leakage)\n",
        "pca = PCA(n_components=2, random_state=SEED)\n",
        "Z = pca.fit_transform(X_train_np)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(Z[:, 0], Z[:, 1], alpha=0.6)\n",
        "plt.title(\"PCA of preprocessed features (train set)\")\n",
        "plt.xlabel(\"PC1\")\n",
        "plt.ylabel(\"PC2\")\n",
        "plt.grid(True, alpha=0.2)\n",
        "plt.show()\n",
        "\n",
        "print(\"Explained variance ratio:\", pca.explained_variance_ratio_)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "IMv-oj2HKkiT",
      "metadata": {
        "id": "IMv-oj2HKkiT"
      },
      "source": [
        "Looking at the PCA visualization, students do NOT form distinct clusters by academic pillar.\n",
        "The different pillars are intermixed throughout the 2D space, suggesting that students from\n",
        "different majors have similar patterns in terms of grit, CGPA, study habits, and technical\n",
        "readiness. This indicates that academic pillar alone is not a strong differentiator in this dataset.\n",
        "\n",
        "PCA does not tell us:\n",
        "1. **Causality**: It doesn't explain WHY students are positioned where they are\n",
        "2. **Feature importance**: We can't tell which original features contribute most to success\n",
        "3. **Prediction**: PCA is for visualization, not for predicting final scores\n",
        "4. **Outliers**: Individual struggling students may not be visible in the aggregate view\n",
        "\n",
        "Additionally, PCA only captures 40% of the variance (PC1+PC2), meaning 60% of the\n",
        "information is lost in this 2D projection."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a168f21",
      "metadata": {
        "id": "2a168f21"
      },
      "source": [
        "## 9) The “At‑Risk Intervention Alert” (agentic add‑on)\n",
        "\n",
        "In educational data mining, prediction is only useful if it leads to **action**.\n",
        "\n",
        "Design a function that:\n",
        "- identifies at-risk students\n",
        "- outputs a **pedagogical recommendation** (specific + actionable)\n",
        "\n",
        "Examples of recommendations:\n",
        "- “Review Python basics: `2 % 3`, loops, lists”\n",
        "- “Attend Week 1–2 recap clinic”\n",
        "- “Form a project team early + schedule 2h/week study block”\n",
        "\n",
        "⚠️ Ethics: the alert should be supportive, not punitive.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a554885",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9a554885",
        "outputId": "b5e4c441-167d-47be-e568-7d0fd4954cdf"
      },
      "outputs": [],
      "source": [
        "def recommend_intervention(row, predicted_score=None, threshold=70):\n",
        "    '''Return (risk_level, recommendation).\n",
        "\n",
        "    TODO: tune rules based on your EDA + model.\n",
        "    '''\n",
        "\n",
        "    # Example rule-based scaffold\n",
        "    if predicted_score is not None and predicted_score < threshold:\n",
        "        # Customize these rules\n",
        "        if row.get(\"hours_per_week_planned\") is not None and row.get(\"hours_per_week_planned\") < 5:\n",
        "            return \"high\", \"Increase weekly study plan to 6–8h; block it on your calendar.\"\n",
        "        if row.get(\"cgpa\") is not None and row.get(\"cgpa\") < 3.5:\n",
        "            return \"high\", \"Book a consult with TA; focus on foundations + weekly practice.\"\n",
        "        return \"medium\", \"Do the Week 1–2 refresher worksheet + attend office hours.\"\n",
        "\n",
        "    return \"low\", \"Keep up the good work; consider helping peers or taking stretch tasks.\"\n",
        "\n",
        "\n",
        "# Demo on one row (replace `predicted_score` with your model output)\n",
        "example = df.iloc[0].to_dict()\n",
        "recommend_intervention(example, predicted_score=65)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "935f2d13",
      "metadata": {
        "id": "935f2d13"
      },
      "source": [
        "## Submission checklist\n",
        "\n",
        "Your notebook should:\n",
        "- run end-to-end without errors\n",
        "- include clear plots + short written interpretation\n",
        "- include feature engineering + justification\n",
        "- include a PyTorch `nn.Linear` model with training loop\n",
        "- include evaluation metrics + a short discussion of limitations\n",
        "- include the at-risk intervention function + ethical reflection\n",
        "\n",
        "---\n",
        "\n",
        "### Reflection prompts (write 3–6 sentences)\n",
        "- What would make this model *unsafe* to deploy in real life?\n",
        "- Which student groups might be disadvantaged by these features?\n",
        "- What additional data would you want, and why?\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
